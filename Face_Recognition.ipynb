{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nayanpatel009/Assignment/blob/main/Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7n109-gfKsJ",
        "outputId": "a2c8024a-7326-4509-fa55-fb7e464eb302",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install face_recognition\n",
        "import face_recognition\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "uFWzknOsav37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66149f0-76c3-4f63-a5fd-af20ff8600af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.24.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 100.1 MB 23 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.21.6)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566186 sha256=a2c04b0609c66f85750292da94dce24100faa18efe03ba3d395942a3ad5a6d6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feAfj-5Gib9J",
        "outputId": "a229b2ae-2031-4682-ed38-0b2c1db89073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9oEs4j1ivxk"
      },
      "source": [
        "path='/content/drive/My Drive/Colab Notebooks'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WTJ__FHi4mY"
      },
      "source": [
        "import os\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbYplJagkWc2"
      },
      "source": [
        "# Get Image names stored in \"Images\" folder\n",
        "image_path_names=[]\n",
        "person_names=set()\n",
        "for file_name in glob.glob(path+'/Imageknown/**.jpg'):\n",
        "  image_path_names.append(file_name)\n",
        "  person_names.add(image_path_names[-1].split('/')[-1].split('_')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0VQO0oRkoKe",
        "outputId": "ab837ff9-6cd4-417e-be78-8c28734e5f33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(image_path_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzJua7rHll-Q",
        "outputId": "fa459ca0-6070-486a-c781-8c74649d5f99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "person_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Aaron Peirsol.jpg',\n",
              " 'Adam Sandler.jpg',\n",
              " 'Adam Scott.jpg',\n",
              " 'Ben Affleck.jpg',\n",
              " 'Donald Trump.jpg',\n",
              " 'Mike Pence.jpg'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrvHS5nkO0VX"
      },
      "source": [
        "  There are total 60 images containing 10 images per person."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDEOeTvSn09H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42087af-c96a-4049-a67e-0675e258add9"
      },
      "source": [
        "# Download Dlib CNN face detector\n",
        "! wget http://dlib.net/files/mmod_human_face_detector.dat.bz2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-11 01:06:54--  http://dlib.net/files/mmod_human_face_detector.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 694709 (678K)\n",
            "Saving to: ‘mmod_human_face_detector.dat.bz2’\n",
            "\n",
            "\r          mmod_huma   0%[                    ]       0  --.-KB/s               \rmmod_human_face_det 100%[===================>] 678.43K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-10-11 01:06:54 (10.6 MB/s) - ‘mmod_human_face_detector.dat.bz2’ saved [694709/694709]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ntLNPejsPU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a93768-947b-4a0e-cd1c-7f76756a013b"
      },
      "source": [
        "!bzip2 -dk mmod_human_face_detector.dat.bz2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bzip2: Output file mmod_human_face_detector.dat already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugCOCE_lsTlP"
      },
      "source": [
        "%rm mmod_human_face_detector.dat.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bRbWm4KlvMU"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import dlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdo0aJNkA_sy"
      },
      "source": [
        "# Load CNN face detector into dlib\n",
        "dnnFaceDetector=dlib.cnn_face_detection_model_v1(\"mmod_human_face_detector.dat\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21_IVMOgybPU"
      },
      "source": [
        "os.mkdir(path+'/Imageknown/**.jpg/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvnDaqCDIqmL"
      },
      "source": [
        "# For each person create a separate folder\n",
        "for person in person_names:\n",
        "  os.mkdir(path+'/Imageknown/**.jpg/'+person+'/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDUaECnUHp4r"
      },
      "source": [
        "# Detect face, crop detected face and save them in corresponding person folder\n",
        "for file_name in image_path_names:\n",
        "  img=cv2.imread(file_name)\n",
        "  gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  rects=dnnFaceDetector(gray,1)\n",
        "  left,top,right,bottom=0,0,0,0\n",
        "  for (i,rect) in enumerate(rects):\n",
        "    left=rect.rect.left() #x1\n",
        "    top=rect.rect.top() #y1\n",
        "    right=rect.rect.right() #x2\n",
        "    bottom=rect.rect.bottom() #y2\n",
        "  width=right-left\n",
        "  height=bottom-top\n",
        "  img_crop=img[top:top+height,left:left+width]\n",
        "  img_path=path+'/Images_crop/'+file_name.split('/')[-1].split('_')[0]+'/'+file_name.split('/')[-1]\n",
        "  cv2.imwrite(img_path,img_crop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0B5EsUzQIIZ"
      },
      "source": [
        "# Get Image names for testing\n",
        "test_image_path_names=[]\n",
        "for file_name in glob.glob(path+'/unknown/**.jpg'):\n",
        "  test_image_path_names.append(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhLxtZuDRD-3",
        "outputId": "9ba8992d-25cd-41a1-85e2-702f3a9c2ac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(test_image_path_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4g5jL7iRWdh"
      },
      "source": [
        "For each person 3 images to test in Images_test folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXjqG2ZnRFTD"
      },
      "source": [
        "os.mkdir(path+'/Test_Images_crop0/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff0ekPxwRwWG"
      },
      "source": [
        "# Create Separate folder for each person in \"Test_Images_crop\" folder\n",
        "for person in person_names:\n",
        "  os.mkdir(path+'/Test_Images_crop0/'+person+'/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kjc0zokR12L"
      },
      "source": [
        "# Detect face,crop face and save in corresponding folder\n",
        "for file_name in test_image_path_names:\n",
        "  img=cv2.imread(file_name)\n",
        "  gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  rects=dnnFaceDetector(gray,1)\n",
        "  left,top,right,bottom=0,0,0,0\n",
        "  for (i,rect) in enumerate(rects):\n",
        "    left=rect.rect.left() #x1\n",
        "    top=rect.rect.top() #y1\n",
        "    right=rect.rect.right() #x2\n",
        "    bottom=rect.rect.bottom() #y2\n",
        "  width=right-left\n",
        "  height=bottom-top\n",
        "  img_crop=img[top:top+height,left:left+width]\n",
        "  img_path=path+'/Test_Images_crop/'+file_name.split('/')[-1].split('_')[0]+'/'+file_name.split('/')[-1]\n",
        "  cv2.imwrite(img_path,img_crop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2vsqwHc4msl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b060ff0-d0ca-4115-a36c-c69dfaecac04"
      },
      "source": [
        "! pip install gdown"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SofaX67Q-b0i",
        "outputId": "2bc29845-baa6-4653-eed1-7b0437e55cea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Download pre-trained vgg-face-model-weights as .h5 file\n",
        "! gdown https://drive.google.com/uc?id=1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo\n",
            "To: /content/drive/My Drive/Colab Notebooks/vgg_face_weights.h5\n",
            "100% 580M/580M [00:07<00:00, 77.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbuvd_mX-lXD"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF0i2mrxBTR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d803c930-6190-499b-89b4-cda4a6163638"
      },
      "source": [
        "! pip install tensorflow==2.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.0.0\n",
            "  Downloading tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (86.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3 MB 61 kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.1.2)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "  Downloading tensorboard-2.0.2-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.21.6)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "  Downloading tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449 kB)\n",
            "\u001b[K     |████████████████████████████████| 449 kB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.14.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.49.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.37.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.0.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=d802e0c49a23b938b108e09d30887a46066173b08be8e4983968150ef386246c\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220929150707\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220929150707:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220929150707\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp8xv8XO_JTS"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import ZeroPadding2D,Convolution2D,MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense,Dropout,Softmax,Flatten,Activation,BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4_j4qVk_Pze"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
        "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Convolution2D(2622, (1, 1)))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7k9g_wtCUfD",
        "outputId": "91ce855c-aff7-407a-ff13-58d8f9ac99e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "zero_padding2d (ZeroPadding2 (None, 226, 226, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPaddin (None, 226, 226, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 114, 114, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPaddin (None, 114, 114, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPaddin (None, 58, 58, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPaddin (None, 58, 58, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPaddin (None, 58, 58, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPaddin (None, 30, 30, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPaddin (None, 30, 30, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPaddin (None, 30, 30, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_10 (ZeroPaddi (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPaddi (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPaddi (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 1, 1, 4096)        102764544 \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 1, 4096)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 1, 4096)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 1, 1, 2622)        10742334  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2622)              0         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 2622)              0         \n",
            "=================================================================\n",
            "Total params: 145,002,878\n",
            "Trainable params: 145,002,878\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ21pD4FDLkT"
      },
      "source": [
        "# Remove Last Softmax layer and get model upto last flatten layer with outputs 2622 units\n",
        "vgg_face=Model(inputs=model.layers[0].input,outputs=model.layers[-2].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zSqFno_Epfz"
      },
      "source": [
        "#Prepare Training Data\n",
        "x_train=[]\n",
        "y_train=[]\n",
        "person_folders=os.listdir(path+'/Images_crop/')\n",
        "person_rep=dict()\n",
        "for i,person in enumerate(person_folders):\n",
        "  person_rep[i]=person\n",
        "  image_names=os.listdir('Images_crop/'+person+'/')\n",
        "  for image_name in image_names:\n",
        "    img=load_img(path+'/Images_crop/'+person+'/'+image_name,target_size=(224,224))\n",
        "    img=img_to_array(img)\n",
        "    img=np.expand_dims(img,axis=0)\n",
        "    img=preprocess_input(img)\n",
        "    img_encode=vgg_face(img)\n",
        "    x_train.append(np.squeeze(K.eval(img_encode)).tolist())\n",
        "    y_train.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cl8ewCNRRCu",
        "outputId": "c2798366-8c0a-4315-91fd-1573eb92589c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "person_rep"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Mike Pence.jpg',\n",
              " 1: 'Donald Trump.jpg',\n",
              " 2: 'Adam Sandler.jpg',\n",
              " 3: 'Ben Affleck.jpg',\n",
              " 4: 'Adam Scott.jpg',\n",
              " 5: 'Aaron Peirsol.jpg'}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyxgU05lSX4D"
      },
      "source": [
        "x_train=np.array(x_train)\n",
        "y_train=np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aylVlQO2SZXB"
      },
      "source": [
        "#Prepare Test Data\n",
        "x_test=[]\n",
        "y_test=[]\n",
        "person_folders=os.listdir(path+'/Test_Images_crop0/')\n",
        "for i,person in enumerate(person_folders):\n",
        "  image_names=os.listdir('Test_Images_crop0/'+person+'/')\n",
        "  for image_name in image_names:\n",
        "    img=load_img(path+'/Test_Images_crop0/'+person+'/'+image_name,target_size=(224,224))\n",
        "    img=img_to_array(img)\n",
        "    img=np.expand_dims(img,axis=0)\n",
        "    img=preprocess_input(img)\n",
        "    img_encode=vgg_face(img)\n",
        "    x_test.append(np.squeeze(K.eval(img_encode)).tolist())\n",
        "    y_test.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4NNw5lqTuKL"
      },
      "source": [
        "x_test=np.array(x_test)\n",
        "y_test=np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAT3ehPVT-24"
      },
      "source": [
        "# Save test and train data for later use\n",
        "np.save('train_data',x_train)\n",
        "np.save('train_labels',y_train)\n",
        "np.save('test_data',x_test)\n",
        "np.save('test_labels',y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ5aWACqUnX3"
      },
      "source": [
        "# Load saved data\n",
        "x_train=np.load('train_data.npy')\n",
        "y_train=np.load('train_labels.npy')\n",
        "x_test=np.load('test_data.npy')\n",
        "y_test=np.load('test_labels.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZOEaNOb0qxD"
      },
      "source": [
        "# Softmax regressor to classify images based on encoding \n",
        "classifier_model=Sequential()\n",
        "classifier_model.add(Dense(units=100,input_dim=x_train.shape[1],kernel_initializer='glorot_uniform'))\n",
        "classifier_model.add(BatchNormalization())\n",
        "classifier_model.add(Activation('tanh'))\n",
        "classifier_model.add(Dropout(0.3))\n",
        "classifier_model.add(Dense(units=10,kernel_initializer='glorot_uniform'))\n",
        "classifier_model.add(BatchNormalization())\n",
        "classifier_model.add(Activation('tanh'))\n",
        "classifier_model.add(Dropout(0.2))\n",
        "classifier_model.add(Dense(units=6,kernel_initializer='he_uniform'))\n",
        "classifier_model.add(Activation('softmax'))\n",
        "classifier_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='nadam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6_DyNnVAHuM"
      },
      "source": [
        "# Path to folder which contains images to be tested and predicted\n",
        "test_images_path=path+'/unknown/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aYRHru9AtfM"
      },
      "source": [
        "dnnFaceDetector=dlib.cnn_face_detection_model_v1(\"mmod_human_face_detector.dat\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJZg7e93Cgu1"
      },
      "source": [
        "def plot(img):\n",
        "  plt.figure(figsize=(8,4))\n",
        "  plt.imshow(img[:,:,::-1])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wofuBLTOH7Iu"
      },
      "source": [
        "person_rep={0:'Narendra Modi',1:'Donald Trump',2:'Angela Merkel',3:'Xi Jinping',4:'Lakshmi Narayana',5:'Vladimir Putin'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M57Q7chO_Xc"
      },
      "source": [
        "os.mkdir(path+'/Predictions4')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}